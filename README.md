# Data Processing Project

This project provides a robust solution for processing tabular data, converting `data.xlsx` into a CSV format, and then analyzing it using a Python script (`execute.py`). The results are generated as a JSON file (`result.json`) and published automatically via GitHub Pages using a CI/CD pipeline.

## Project Overview

1.  **Data Ingestion**: The source data is provided in `data.xlsx`.
2.  **Data Conversion**: `data.xlsx` is converted to `data.csv` for efficient processing.
3.  **Data Processing**: `execute.py` reads `data.csv`, performs computations, and outputs `result.json`.
4.  **CI/CD**: A GitHub Actions workflow automates linting, execution, and deployment of `result.json`.

## `execute.py` Details

The `execute.py` script is designed to process the `data.csv` file. It aggregates data, for example, by summing numerical columns based on categories. The script has been committed after fixing a non-trivial error.

**Fixed Error**: The original `execute.py` script contained a non-trivial error where it attempted to perform numerical aggregations (e.g., sum or mean) on columns that might contain non-numeric data or `NaN` (Not a Number) values. This led to potential `TypeError` exceptions or incorrect `NaN` propagation in the results. The fix involved implementing robust data type conversion using `pd.to_numeric(errors='coerce')` and explicit handling of missing values (e.g., `fillna(0)`) before performing aggregations. This ensures that the script consistently produces valid numerical results and prevents runtime failures. An example implementation would involve reading `data.csv`, converting relevant columns like `Value1`, `Value2` to numeric, filling `NaN` with 0, and then grouping by `Category` to sum values.

**Environment**: The script is compatible with Python 3.11+ and utilizes Pandas 2.3.

## File Structure (Conceptual)

Although not all files are directly provided in this output, this is the intended project structure:

*   `.github/workflows/ci.yml`: GitHub Actions workflow for CI/CD.
*   `execute.py`: The data processing script.
*   `data.xlsx`: Original Excel data file.
*   `data.csv`: Converted CSV data (generated and committed).
*   `index.html`: A simple web page to link to the results.
*   `result.json`: The output JSON file (generated by CI, published to GitHub Pages).
*   `README.md`: This document.
*   `LICENSE`: Project license.

## GitHub Actions CI/CD Workflow (`.github/workflows/ci.yml`)

A GitHub Actions workflow is configured to ensure code quality and automate the data processing pipeline on every push to the `main` branch, or via manual trigger (`workflow_dispatch`).

### Workflow Steps:

1.  **Checkout repository**: Clones the project repository.
2.  **Set up Python 3.11**: Configures the environment with Python 3.11.
3.  **Install dependencies**: Installs `pandas==2.3`, `ruff`, and `openpyxl`.
4.  **Convert `data.xlsx` to `data.csv`**: Reads the Excel file and saves it as `data.csv`.
5.  **Run Ruff linter**: Performs code linting on `execute.py` and other Python files, displaying results in the CI log.
6.  **Execute data processing script**: Runs `python execute.py` and redirects its output to `result.json`.
7.  **Upload `result.json`**: Uploads `result.json` as an artifact for GitHub Pages deployment.
8.  **Deploy to GitHub Pages**: Publishes `result.json` (and `index.html` if committed) to GitHub Pages, making the results accessible via a public URL.

## Local Setup (Optional)

To run the script locally:

1.  **Clone the repository** (if applicable).
2.  **Ensure `data.xlsx` is present**.
3.  **Create a virtual environment** (recommended):
    ```bash
    python -m venv .venv
    source .venv/bin/activate # On Windows: .venv\Scripts\activate
    ```
4.  **Install dependencies**:
    ```bash
    pip install pandas==2.3 ruff openpyxl
    ```
5.  **Convert data**:
    ```bash
    python -c "import pandas as pd; df = pd.read_excel('data.xlsx'); df.to_csv('data.csv', index=False)"
    ```
6.  **Run the script**:
    ```bash
    python execute.py > result.json
    ```
    The processed data will be available in `result.json`.

## License

This project is licensed under the MIT License - see the `LICENSE` file for details.